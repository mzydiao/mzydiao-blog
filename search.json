[
  {
    "objectID": "research/thesis/index.html",
    "href": "research/thesis/index.html",
    "title": "Proximal Gradient Algorithms for Gaussian Variational Inference: Optimization in the Bures–Wasserstein Space",
    "section": "",
    "text": "Links\nSee my thesis on MIT DSpace (2023).\n\n\n\nThesis cover page\n\n\nThe work done in this thesis was published at ICML 2023 (2023).\n\n\n\n\n\nReferences\n\nDiao, Michael Ziyang. 2023. “Proximal Gradient Algorithms for Gaussian Variational Inference: Optimization in the Bures–Wasserstein Space.” Master’s thesis, Massachusetts Institute of Technology.\n\n\nDiao, Michael Ziyang, Krishna Balasubramanian, Sinho Chewi, and Adil Salim. 2023. “Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space.” In Proceedings of the 40th International Conference on Machine Learning, 202:7960–91. Proceedings of Machine Learning Research. PMLR. https://proceedings.mlr.press/v202/diao23a.html."
  },
  {
    "objectID": "research/fbgvi/index.html",
    "href": "research/fbgvi/index.html",
    "title": "Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space",
    "section": "",
    "text": "Links\nPublished at ICML 2023.\nFor a quick overview, check out our ICML poster and video.\nAnd for more detail, see our arXiv preprint (2023) and our ICML paper (2023). :)\n\n\n\n\n\nReferences\n\nDiao, Michael Ziyang, Krishna Balasubramanian, Sinho Chewi, and Adil Salim. 2023. “Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space.” In Proceedings of the 40th International Conference on Machine Learning, 202:7960–91. Proceedings of Machine Learning Research. PMLR. https://proceedings.mlr.press/v202/diao23a.html.\n\n\nDiao, Michael, Krishnakumar Balasubramanian, Sinho Chewi, and Adil Salim. 2023. “Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space.” https://arxiv.org/abs/2304.05398."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space\n\n\n\n\n\n\n\npapers\n\n\nICML\n\n\n\n\nWe devise a novel algorithm for Gaussian variational inference that comes with state-of-the-art convergence guarantees.\n\n\n\n\n\n\nJul 23, 2023\n\n\nMichael Diao\n\n\n\n\n\n\n  \n\n\n\n\nProximal Gradient Algorithms for Gaussian Variational Inference: Optimization in the Bures–Wasserstein Space\n\n\n\n\n\n\n\nthesis\n\n\n\n\nMy MEng thesis. Translates the machinery of Euclidean optimization to the Bures-Wasserstein space to develop state-of-the-art algorithms for Gaussian variational inference.\n\n\n\n\n\n\nMay 12, 2023\n\n\nMichael Diao\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/score-matching/index.html",
    "href": "posts/score-matching/index.html",
    "title": "Challenges of Score Matching",
    "section": "",
    "text": "Modern day models are incredibly rich and expressive, powering contemporary advances in machine learning and statistical inference. The idea of modelling is that we are given some data X_1, \\ldots, X_n \\in \\mathcal X and want to get a handle on the underlying distribution that generates the data. To do this, one approach is parametric inference: we take a family of distributions \\mathcal Q= \\left\\{ q_{\\theta} \\colon \\theta \\in \\Theta \\right\\} indexed by a parameter \\theta \\in \\Theta. We assume for simplicity that X_1, \\ldots, X_n are drawn i.i.d. from q_{\\theta^\\star} for some true parameter \\theta^\\star where \\theta^\\star \\in \\Theta. Based on our data, we seek to produce an estimate \\hat \\theta of the true parameter \\theta^\\star.\n\n\nOne such estimate is the maximum likelihood estimate (MLE), which is the element of \\Theta that maximizes the likelihood (or equivalently log-likelihood) of the data: \\begin{aligned}\n    \\hat \\theta_{\\text{MLE}}\n    \\overset{\\mathrm{def}}{=}\\mathop{\\mathrm{arg max}}_{\\theta \\in \\Theta} \\prod_{i=1}^{n} q_\\theta(X_i)\n    = \\mathop{\\mathrm{arg max}}_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} \\underbrace{\\log q_\\theta(X_i)}_{\\overset{\\mathrm{def}}{=}\\ell(\\theta; X_i)}.\n\\end{aligned} As n \\to \\infty, by the Law of Large Numbers, we have that \\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n} \\ell(\\theta; X_i) \\overset{\\mathbb P}{\\to} \\mathbb E[\\ell(\\theta; X_1)] = \\mathbb E[\\log q_\\theta(X_1)].\n\\end{aligned} On the other hand, we have that \\begin{aligned}\n    \\mathbb E[\\log q_{\\theta^\\star}(X_1)] -\n    \\mathbb E[\\log q_{\\theta}(X_1)]\n    =\n    \\mathbb E\\left[ \\log \\frac{q_{\\theta^\\star}}{q_{\\theta}}(X_1) \\right]\n    =\n    \\mathsf{KL}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_{\\theta}\\right),\n\\end{aligned} where \\mathsf{KL}\\left(p \\,\\Vert\\, q\\right) denotes the KL divergence between distributions p and q. The KL divergence between two distinct distributions is positive, meaning that for any \\theta, \\theta^\\star for which q_\\theta \\neq q_{\\theta^\\star}, we have \\mathsf{KL}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_\\theta\\right) &gt; 0. So as n \\to \\infty, the MLE \\hat \\theta_{\\text{MLE}} will converge in probability to the true parameter \\theta^\\star: in other words, the MLE is a consistent estimator. Furthermore, the MLE is asymptotically efficient: that is, no other estimator attains a strictly lower variance than the MLE as n \\to \\infty.\nHowever, the richness of models comes at a cost. Often, the parameterized distribution q_\\theta can only be specified up to a constant of proportionality. For instance, we might specify that q_\\theta(x) \\propto \\exp(-V_\\theta(x)) for some log-potential function V_\\theta \\colon \\mathcal X\\to \\mathbb R. Since q_{\\theta} is a probability distribution, it must sum to 1, meaning that we have \\begin{aligned}\n    q_{\\theta} = \\frac{\\exp(-V_\\theta(x))}{Z(\\theta)},  \\qquad \\text{where} \\; Z(\\theta) \\overset{\\mathrm{def}}{=}\\int_{\\mathcal X} \\exp(-V_{\\theta}(x'))\\,\\mathrm{d}{x'}.\n\\end{aligned} The issue is that for each value of \\theta, there is a different normalization constant Z(\\theta), and computing even a single normalization constant is generally intractable when the data space \\mathcal X is large. Computing the MLE falls victim to this issue: if we cannot compute Z(\\theta), then there is no hope of computing \\hat \\theta_{\\text{MLE}} because the objective function depends on the value of Z(\\theta).\n\n\n\nThe score matching estimator (SME), introduced by Hyvärinen (2005), promises to solve this issue. The SME is defined by \\begin{aligned}\n    \\hat \\theta _{\\text{SME}}\n    \\overset{\\mathrm{def}}{=}\\mathop{\\mathrm{arg min}}_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n}\n    \\biggl[\n    \\underbrace{\n      \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_i)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_i) \\right\\rVert^2\n    }_{\\overset{\\mathrm{def}}{=}\\varphi (\\theta; X_i)}\n    \\biggr].\n\\end{aligned} The quantity \\nabla \\log q_\\theta is known as the score function of q_\\theta. Since the gradient is taken with respect to x rather than \\theta, the normalization constant vanishes altogether from the objective function: hence, the score matching estimator indeed evades the need to normalize, giving it one computational advantage over the MLE.\nNow the question is: is this estimator any good? How do its statistical properties compare to the MLE?\nAs a first consideration, the SME is indeed a consistent estimator, just like the MLE. Indeed, we have that by the Law of Large Numbers, \\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n}\n    \\rho(\\theta; X_i)\n    &=\n    \\frac{1}{n} \\sum_{i=1}^{n}\n    \\left[\n    \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_i)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_i) \\right\\rVert^2\n    \\right]\n    \\\\\n    &\\overset{\\mathbb P}{\\to}\n    \\mathbb E\n    \\left[ \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_1)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_1) \\right\\rVert^2 \\right]\n    \\\\\n    &=\n    \\frac{1}{2}\\Bigl(\\underbrace{\n    \\mathbb E\\left\\lVert \\nabla \\log \\frac{q_{\\theta^\\star}}{q_\\theta}(X_1) \\right\\rVert^2\n    }_{= \\mathsf{FI}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_\\theta\\right)}\n    -\n    \\mathbb E\\left\\lVert \\nabla \\log q_{\\theta^\\star}(X_1) \\right\\rVert^2\n    \\Bigr)\n    ,\n\\end{aligned} where the last equality follows by integration by parts. The first term on the last line is the relative Fisher information (FI) between q_{\\theta^\\star} and q_{\\theta}, and is nonnegative with equality iff q_{\\theta^\\star} = q_\\theta. Hence, asymptotically \\theta^\\star attains minimality of the objective, meaning that \\hat \\theta_{\\text{SME}} is indeed consistent.\nThe story thus far looks good. Not only does the SME relieve the computational burden of evaluating the normalization constant, but it also provides a consistent estimator. Might it be the case that we can always just use the SME instead of the MLE?\nUnfortunately, we must dash our hopes. The core idea of score matching is that if the score functions \\nabla \\log q_{\\theta^\\star} and \\nabla \\log q_{\\theta} match exactly, then the distributions q_{\\theta^\\star} and q_{\\theta} must match as well. However, there is a key issue. The score function, being a gradient, is fundamentally a measure of local information about the change in the log-likelihood function. Meanwhile, it is possible for two very different distributions to have extremely similar log-likelihood functions (up to a constant shift) outside of a set of very small measure. Until enough samples land in that distinguishing set, score matching cannot discern the difference between these two distributions.\nThis is the key intuition behind the statistical inefficiency of score matching: when \\left\\{ q_{\\theta} \\right\\} is a family of distributions exhibiting the aforementioned behavior — having similar score functions outside a set of negligible measure — the SME can have extremely high variance compared with the MLE. As it turns out, this behavior is deeply related to the maximal log-Sobolev constant among distributions in \\left\\{ q_\\theta \\right\\}; see the work of Koehler, Heckett, and Risteski (2022) for a discussion.\nIn the sequel, we will make our intuitive argument concrete by demonstrating that score matching is indeed statistically inefficient on a simple example of mixtures of well-separated Gaussians — a prototypical example of a distribution with large log-Sobolev constant."
  },
  {
    "objectID": "posts/score-matching/index.html#maximum-likelihood-estimation",
    "href": "posts/score-matching/index.html#maximum-likelihood-estimation",
    "title": "Challenges of Score Matching",
    "section": "",
    "text": "One such estimate is the maximum likelihood estimate (MLE), which is the element of \\Theta that maximizes the likelihood (or equivalently log-likelihood) of the data: \\begin{aligned}\n    \\hat \\theta_{\\text{MLE}}\n    \\overset{\\mathrm{def}}{=}\\mathop{\\mathrm{arg max}}_{\\theta \\in \\Theta} \\prod_{i=1}^{n} q_\\theta(X_i)\n    = \\mathop{\\mathrm{arg max}}_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} \\underbrace{\\log q_\\theta(X_i)}_{\\overset{\\mathrm{def}}{=}\\ell(\\theta; X_i)}.\n\\end{aligned} As n \\to \\infty, by the Law of Large Numbers, we have that \\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n} \\ell(\\theta; X_i) \\overset{\\mathbb P}{\\to} \\mathbb E[\\ell(\\theta; X_1)] = \\mathbb E[\\log q_\\theta(X_1)].\n\\end{aligned} On the other hand, we have that \\begin{aligned}\n    \\mathbb E[\\log q_{\\theta^\\star}(X_1)] -\n    \\mathbb E[\\log q_{\\theta}(X_1)]\n    =\n    \\mathbb E\\left[ \\log \\frac{q_{\\theta^\\star}}{q_{\\theta}}(X_1) \\right]\n    =\n    \\mathsf{KL}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_{\\theta}\\right),\n\\end{aligned} where \\mathsf{KL}\\left(p \\,\\Vert\\, q\\right) denotes the KL divergence between distributions p and q. The KL divergence between two distinct distributions is positive, meaning that for any \\theta, \\theta^\\star for which q_\\theta \\neq q_{\\theta^\\star}, we have \\mathsf{KL}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_\\theta\\right) &gt; 0. So as n \\to \\infty, the MLE \\hat \\theta_{\\text{MLE}} will converge in probability to the true parameter \\theta^\\star: in other words, the MLE is a consistent estimator. Furthermore, the MLE is asymptotically efficient: that is, no other estimator attains a strictly lower variance than the MLE as n \\to \\infty.\nHowever, the richness of models comes at a cost. Often, the parameterized distribution q_\\theta can only be specified up to a constant of proportionality. For instance, we might specify that q_\\theta(x) \\propto \\exp(-V_\\theta(x)) for some log-potential function V_\\theta \\colon \\mathcal X\\to \\mathbb R. Since q_{\\theta} is a probability distribution, it must sum to 1, meaning that we have \\begin{aligned}\n    q_{\\theta} = \\frac{\\exp(-V_\\theta(x))}{Z(\\theta)},  \\qquad \\text{where} \\; Z(\\theta) \\overset{\\mathrm{def}}{=}\\int_{\\mathcal X} \\exp(-V_{\\theta}(x'))\\,\\mathrm{d}{x'}.\n\\end{aligned} The issue is that for each value of \\theta, there is a different normalization constant Z(\\theta), and computing even a single normalization constant is generally intractable when the data space \\mathcal X is large. Computing the MLE falls victim to this issue: if we cannot compute Z(\\theta), then there is no hope of computing \\hat \\theta_{\\text{MLE}} because the objective function depends on the value of Z(\\theta)."
  },
  {
    "objectID": "posts/score-matching/index.html#score-matching",
    "href": "posts/score-matching/index.html#score-matching",
    "title": "Challenges of Score Matching",
    "section": "",
    "text": "The score matching estimator (SME), introduced by Hyvärinen (2005), promises to solve this issue. The SME is defined by \\begin{aligned}\n    \\hat \\theta _{\\text{SME}}\n    \\overset{\\mathrm{def}}{=}\\mathop{\\mathrm{arg min}}_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n}\n    \\biggl[\n    \\underbrace{\n      \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_i)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_i) \\right\\rVert^2\n    }_{\\overset{\\mathrm{def}}{=}\\varphi (\\theta; X_i)}\n    \\biggr].\n\\end{aligned} The quantity \\nabla \\log q_\\theta is known as the score function of q_\\theta. Since the gradient is taken with respect to x rather than \\theta, the normalization constant vanishes altogether from the objective function: hence, the score matching estimator indeed evades the need to normalize, giving it one computational advantage over the MLE.\nNow the question is: is this estimator any good? How do its statistical properties compare to the MLE?\nAs a first consideration, the SME is indeed a consistent estimator, just like the MLE. Indeed, we have that by the Law of Large Numbers, \\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n}\n    \\rho(\\theta; X_i)\n    &=\n    \\frac{1}{n} \\sum_{i=1}^{n}\n    \\left[\n    \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_i)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_i) \\right\\rVert^2\n    \\right]\n    \\\\\n    &\\overset{\\mathbb P}{\\to}\n    \\mathbb E\n    \\left[ \\mathop{\\mathrm{Tr}}(\\nabla^2 \\log q_\\theta (X_1)) + \\frac{1}{2}\\left\\lVert \\nabla \\log q_\\theta(X_1) \\right\\rVert^2 \\right]\n    \\\\\n    &=\n    \\frac{1}{2}\\Bigl(\\underbrace{\n    \\mathbb E\\left\\lVert \\nabla \\log \\frac{q_{\\theta^\\star}}{q_\\theta}(X_1) \\right\\rVert^2\n    }_{= \\mathsf{FI}\\left(q_{\\theta^\\star} \\,\\Vert\\, q_\\theta\\right)}\n    -\n    \\mathbb E\\left\\lVert \\nabla \\log q_{\\theta^\\star}(X_1) \\right\\rVert^2\n    \\Bigr)\n    ,\n\\end{aligned} where the last equality follows by integration by parts. The first term on the last line is the relative Fisher information (FI) between q_{\\theta^\\star} and q_{\\theta}, and is nonnegative with equality iff q_{\\theta^\\star} = q_\\theta. Hence, asymptotically \\theta^\\star attains minimality of the objective, meaning that \\hat \\theta_{\\text{SME}} is indeed consistent.\nThe story thus far looks good. Not only does the SME relieve the computational burden of evaluating the normalization constant, but it also provides a consistent estimator. Might it be the case that we can always just use the SME instead of the MLE?\nUnfortunately, we must dash our hopes. The core idea of score matching is that if the score functions \\nabla \\log q_{\\theta^\\star} and \\nabla \\log q_{\\theta} match exactly, then the distributions q_{\\theta^\\star} and q_{\\theta} must match as well. However, there is a key issue. The score function, being a gradient, is fundamentally a measure of local information about the change in the log-likelihood function. Meanwhile, it is possible for two very different distributions to have extremely similar log-likelihood functions (up to a constant shift) outside of a set of very small measure. Until enough samples land in that distinguishing set, score matching cannot discern the difference between these two distributions.\nThis is the key intuition behind the statistical inefficiency of score matching: when \\left\\{ q_{\\theta} \\right\\} is a family of distributions exhibiting the aforementioned behavior — having similar score functions outside a set of negligible measure — the SME can have extremely high variance compared with the MLE. As it turns out, this behavior is deeply related to the maximal log-Sobolev constant among distributions in \\left\\{ q_\\theta \\right\\}; see the work of Koehler, Heckett, and Risteski (2022) for a discussion.\nIn the sequel, we will make our intuitive argument concrete by demonstrating that score matching is indeed statistically inefficient on a simple example of mixtures of well-separated Gaussians — a prototypical example of a distribution with large log-Sobolev constant."
  },
  {
    "objectID": "posts/score-matching/index.html#inefficiency-of-score-matching",
    "href": "posts/score-matching/index.html#inefficiency-of-score-matching",
    "title": "Challenges of Score Matching",
    "section": "Inefficiency of score matching",
    "text": "Inefficiency of score matching\nThe following theorem shows that the SME is statistically inefficient compared to the MLE for learning the parameter p:\n\n\n\n\n\n\n\nTheorem 1 (Inefficiency of score matching) Suppose that p^\\star = \\frac{1}{2} and that X \\sim \\mu_{p^\\star}. Then as n \\to \\infty, we have that \\begin{aligned}\n        {\\sqrt{n}} (\\hat p_{\\text{SME}} - p^\\star) \\overset{\\text{D}}{\\to} \\mathcal N(0, \\sigma^2_{\\text{SME}}(m)),\n\\end{aligned} where \\sigma^2_{\\text{SME}}(m) \\in \\Omega(m^2 e^{-\\frac{1}{2}m^2}). On the other hand, \\begin{aligned}\n        {\\sqrt{n}} (\\hat p_{\\text{MLE}} - p^\\star) \\overset{\\text{D}}{\\to} \\mathcal N\\left( 0, \\sigma^2_{\\text{MLE}}(m) \\right),\n\\end{aligned} where \\sigma^2_{\\text{MLE}}(m) \\in O(1).\n\n\n\n\nHence, this example of learning the weight parameter of a mixture of one-dimensional standard Gaussians demonstrates an extreme gap in the statistical efficiency of the SME versus the MLE: the standardized asymptotic variance of the SME grows as e^{\\frac{1}{2}m^2} whereas that of the MLE does not grow at all (in fact, shrinks)! The idea is that the MLE learns the weight parameter very easily by simply looking at the proportion of samples landing in the positive real axis versus the negative real axis, and high separation only makes this learning task easier. On the other hand, the SME suffers from the issue we posited earlier: the score functions \\nabla \\log \\mu_p basically do not differ at all except on a small interval around 0, and the measure of this set is extremely small, on the order of e^{-\\frac{1}{2}m^2}.\nIn Section 3.1, we compute the score function \\nabla \\log \\mu_p as well as its partial derivatives with respect to p. Using these formulas, we can obtain our desired bounds. On the other hand, before diving into the proof, we first provide an illustration in Figure 1 that confirms our above intuition.\n\nVisualizing score function for varying p\nWe plot the score functions \\nabla \\log \\mu_p (x) with m = 4.5 for p \\in \\{0.1, 0.5, 0.9\\}, superimposing the mixture PDF to visually demonstrate that the score functions only vary significantly on a set of negligible measure.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef gaussian_pdf(x, mean, sigma):\n    return (\n      1 / (sigma * np.sqrt(2 * np.pi)) *\n      np.exp(-(x - mean) ** 2 / (2 * sigma ** 2))\n    )\n\ndef mixture_pdf(x, mean, sigma, p):\n    # Mixture with weights p\n    mu_plus = gaussian_pdf(x, mean, sigma)\n    mu_minus = gaussian_pdf(x, -mean, sigma)\n    return (p * mu_plus + (1-p) * mu_minus)\n\ndef score_function(x, mean, sigma, p):\n    mu_plus = gaussian_pdf(x, mean, sigma)\n    mu_minus = gaussian_pdf(x, -mean, sigma)\n    pos = p * mu_plus * (- x + mean) / (sigma ** 2)\n    neg = (1-p) * mu_minus * (- x - mean) / (sigma ** 2)\n    return (pos + neg) / (mixture_pdf(x, mean, sigma, p))\n\nx = np.linspace(-10, 10, 1000)\n\n# set the mean and std\nmean = 4.5\nsigma = 1\n\n# Set the weight parameter for the Gaussian mixture\np = 0.5  # Equal weights for the two Gaussians\n\n# Compute the PDF and score function for each x value\npdf = mixture_pdf(x, mean, sigma, p)\n\n# Plotting the Gaussian mixture PDF and score function\nfig, ax1 = plt.subplots()\nblue = '#4287f5'\nax1.axhline(0, color='gray')\nax1.plot(x, pdf, blue, label=r'PDF $\\mu_{p}(x)$, $p = \\frac{1}{2}$')\nax1.set_xlabel(r'$x$')\nax1.set_ylabel('PDF')\nax1.tick_params(axis='y')\n\n# Set symmetric y limits on left\ny_min, y_max = -np.max(pdf) * 1.1, np.max(pdf) * 1.1\nax1.set_ylim(y_min, y_max)\n\n# Plot score functions for different values of p\nax2 = ax1.twinx()\nfor p in np.linspace(0.1, 0.9, 3):\n  color = plt.cm.viridis(p)\n  scores = score_function(x, mean, sigma, p)\n  ax2.plot(x, scores, color=color, label=fr'score $\\nabla \\,\\log \\mu_{{p}}(x)$, $p={p}$', )\nax2.set_ylabel('score')\nax2.tick_params(axis='y')\n\n# Display legend\nlines = ax1.get_lines() + ax2.get_lines()\nplt.legend(lines, [line.get_label() for line in lines], loc='lower left')\n\nplt.title('Gaussian Mixture PDF and Score Function')\nplt.show()\n\n\n\n\n\nFigure 1: The score function varies negligibly with p outside a set of extremely small measure. Hence, learning p via score matching should be extremely sample inefficient."
  },
  {
    "objectID": "posts/score-matching/index.html#proof",
    "href": "posts/score-matching/index.html#proof",
    "title": "Challenges of Score Matching",
    "section": "Proof",
    "text": "Proof\n\nProof (Theorem 1). Define the risk function \\begin{aligned}\n    \\varphi(p; x)\n    &=\n    \\nabla^2 \\log \\mu_p (x) + \\frac{1}{2}(\\nabla \\log \\mu_p (x))^2,\n\\end{aligned} so that \\begin{aligned}\n    \\hat p_{\\text{SME}}\n    = \\mathop{\\mathrm{arg min}}_{p \\in [0, 1]}\n    \\frac{1}{n}\n    \\sum_{i=1}^{n}\n    \\varphi(p, X_i)\n    .\n\\end{aligned} Furthermore, denote \\begin{aligned}\n    \\varphi_n(p) \\overset{\\mathrm{def}}{=}\n    \\frac{1}{n}\n    \\sum_{i=1}^{n}\n    \\varphi(p, X_i).\n\\end{aligned} Now, since the SME is consistent, \\hat p_{\\text{SME}} will be close to p^\\star as n \\to \\infty. This motivates performing a Taylor expansion of the objective function to obtain that \\begin{aligned}\n    0\n    &=\n    \\partial_p \\varphi_n (\\hat p_{\\text{SME}})\n    \\approx\n    \\partial_p \\varphi_n (p^\\star)\n    +\n    \\partial_p^2 \\varphi_n (p^\\star) (\\hat p_{\\text{SME}} - p^\\star).\n\\end{aligned} Rearranging, we obtain that \\begin{aligned}\n    \\sqrt{n}(\\hat p_{\\text{SME}} - p^\\star)\n    \\approx \\frac{\\sqrt{n} \\partial_p \\varphi_n (p^\\star)}{\\partial_p^2 \\varphi_n (p^\\star)}.\n\\end{aligned} Let X \\sim \\mu_{p^\\star}. As n \\to \\infty, the Central Limit Theorem tells us that \\begin{aligned}\n    \\sqrt{n} \\partial_p \\varphi_n (p^\\star)\n    \\overset{\\text{D}}{\\to} \\mathcal N(0, \\mathop{\\mathrm{Var}}\\left[ \\partial_p \\varphi(p; X) \\right])\n    = \\mathcal N(0, \\mathbb E\\left[ (\\partial_p \\varphi(p^\\star; X))^2 \\right]),\n\\end{aligned} where the last equality is due to the fact \\partial_p \\,\\big\\vert_{p = p^\\star}\\mathbb E[\\varphi(p^\\star; X)] = 0 due to asymptotic consistency. On the other hand, by the Law of Large Numbers, the denominator converges to \\begin{aligned}\n    \\partial_p^2 \\varphi_n(p^\\star) = \\mathbb E\\left[ \\partial_p^2 \\varphi(p^\\star; X) \\right].\n\\end{aligned} Thus, we have that \\begin{aligned}\n    \\sqrt{n}(\\hat p - p^\\star)\n    \\overset{\\text{D}}{\\to}\n    \\mathcal N\\left( 0,\n    \\frac{\\mathbb E\\left[ \\left( \\partial_p \\varphi(p; X) \\right)^2 \\right]}{\\mathbb E\\left[ \\partial_p^2 \\varphi(p; X) \\right]^2}\n    \\right).\n\\end{aligned} In fact, we can simplify the denominator of the variance expression. We have that \\begin{aligned}\n    \\mathbb E\\left[ \\partial_p^2 \\varphi(p; X) \\right]\n    &=\n    \\int \\partial_p^2 \\varphi(p; x) \\,\\mathrm{d}{\\mu_p(x)}\\\\\n    &=\n    -\\int \\partial_p \\varphi(p; x) (\\partial_p \\mu_p(x))\\,\\mathrm{d}{x}\n    \\\\\n    &=\n    -\\int \\partial_p \\varphi(p; x) \\left( \\frac{\\partial_p \\mu_p(x)}{\\mu_p(x)} \\right)\\,\\mathrm{d}{\\mu_p(x)}\\\\\n    &=\n    -\\int (\\partial_p \\varphi(p; x)) (\\partial_p \\log \\mu_p (x)) \\,\\mathrm{d}{\\mu_p(x)},\n\\end{aligned} where the second equality is by integration by parts. Hence, \\begin{aligned}\n    \\mathbb E\\left[ \\partial_p^2 \\varphi(p; X) \\right]^2\n    &=\n    \\mathbb E\\left[ \\partial_p \\varphi(p; X) (\\partial_p \\log \\mu_p (x)) \\right]^2.\n\\end{aligned}\nComputing the partial derivative of the risk function with respect to p, we obtain that \\begin{aligned}\n    \\partial_p \\varphi(p; X)\n    &=\n    \\partial_p \\nabla^2 \\log \\mu_p (X)\n    +\n    (\\nabla \\log \\mu_p(X)) (\\partial_p \\nabla \\log \\mu_p(X)).\n\\end{aligned}\nNow, we provide a lower bound on the numerator and an upper bound on the denominator as follows.\n\n\nLower bound on numerator.\n\nUsing the calculations in Section 3.1, we compute that \\begin{aligned}\n    \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert\n    &=\n    \\left\\lvert\n    \\partial_p \\nabla^2 \\log \\mu_p (X)\n    +\n    (\\nabla \\log \\mu_p(X)) (\\partial_p \\nabla \\log \\mu_p(X)) \\right\\rvert\n    \\\\\n    &=\n    \\left\\lvert\n    -\\frac{16m^2}{(e^{mX} + e^{-mX})^2} \\cdot \\tanh(mX) + (-X + m \\tanh(mX)) \\cdot \\frac{8m}{(e^{mX} + e^{-mX})^2}\n     \\right\\rvert\n    \\\\\n    &=\n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left\\lvert\n    X + m \\cdot \\tanh(mX)\n     \\right\\rvert.\n\\end{aligned} Consider when \\left\\lvert X \\right\\rvert \\in [\\frac{1}{2m}, \\frac{1}{m}]. On this interval, we have that \\begin{aligned}\n    \\frac{\\left\\lvert\n    X + m \\cdot \\tanh(mX)\n     \\right\\rvert}{(e^{mX} + e^{-mX})^2}\n    &\\geq\n    \\frac{m \\left\\lvert \\tanh(mX) \\right\\rvert - \\left\\lvert\n    X\n     \\right\\rvert}{(e^{mX} + e^{-mX})^2}\n    \\\\\n    &\\geq\n    \\frac{m \\tanh (1) - \\frac{1}{m}}{(e + e^{-1})^2}\n    \\\\\n    &\\gtrsim\n    m,\n\\end{aligned} where the second inequality is a consequence of the triangle inequality. Thus, on this interval, we have that \\begin{aligned}\n    \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert\n    =\n    \\frac{8m\\left\\lvert\n    X + m \\cdot \\tanh(mX)\n     \\right\\rvert}{(e^{mX} + e^{-mX})^2}\n    \\gtrsim m^2.\n\\end{aligned} Hence, we obtain that \\begin{aligned}\n    \\mathbb E\\left[ \\left( \\partial_p \\varphi(p; X) \\right)^2 \\right]\n    &=\n    \\mathbb E\\left[\n    \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert^2\n    \\right]\n    \\\\\n    &\\geq\n    \\mathbb E\\left[\n    \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert^2\n    \\mathbf 1_{\\left\\lvert X \\right\\rvert\\in [\\frac{1}{2m}, \\frac{1}{m}]}\n    \\right]\n    \\\\\n    &\\gtrsim\n    \\mathbb E\\left[\n    m^4\n    \\mathbf 1_{\\left\\lvert X \\right\\rvert\\leq [\\frac{1}{2m}, \\frac{1}{m}]}\n    \\right]\n    \\\\\n    &\\gtrsim\n    m^4 e^{-\\frac{1}{2}m^2}.\n\\end{aligned}\n\n\n\nUpper bound on denominator.\n\nFirst, using the work above, we have that \\begin{aligned}\n    \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert\n    &=\n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left\\lvert\n    X + m \\cdot \\tanh(mX)\n     \\right\\rvert\n    \\\\\n    &\\leq\n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left(\n    \\left\\lvert\n    X\n     \\right\\rvert + m\n    \\right),\n\\end{aligned} by the triangle inequality. On the other hand, using Section 3.1, we compute that \\begin{aligned}\n    \\left\\lvert \\partial_p \\log \\mu_p (X) \\right\\rvert\n    &=\n    \\left\\lvert 2\\tanh(mX) \\right\\rvert\n    \\leq\n    2.\n\\end{aligned} Hence, we find that \\begin{aligned}\n    \\mathbb E\\left[ (\\partial_p \\varphi(p; X)) (\\partial_p \\log \\mu_p (X)) \\right]\n    &\\leq\n    \\mathbb E\\left[ \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert \\left\\lvert \\partial_p \\log \\mu_p (X) \\right\\rvert \\right]\n    \\\\\n    &\\leq\n    2\n    \\mathbb E\\left[ \\left\\lvert \\partial_p \\varphi(p; X) \\right\\rvert \\right]\n    \\\\\n    &\\lesssim\n    \\mathbb E\\left[\n    \\frac{m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left(\n    \\left\\lvert\n    X\n     \\right\\rvert + m\n    \\right)\n    \\right]\n    \\\\\n    &\\lesssim\n    m\n    \\int_{0}^{\\infty}\n    \\frac{x + m}{(e^{mx} + e^{-mx})^2}\n    \\cdot\n    e^{-\\frac{1}{2}(x - m)^2}\n    \\,\\mathrm{d}{x}\n    \\\\\n    &\\leq\n    m\n    \\int_{0}^{\\infty}\n    \\left(\n    x\n    + m\n    \\right)\n    e^{-\\frac{1}{2}(x - m)^2-2mx}\n    \\,\\mathrm{d}{x}\n    \\\\\n    &\\lesssim\n    me^{-\\frac{1}{2}m^2},\n\\end{aligned} where the last equality is a consequence of Mills’ inequality (a tail bound on the Gaussian CDF).\n\nCombining the upper and lower bounds, we find that the asymptotic variance of the score matching estimator is \\begin{aligned}\n    \\frac{\\mathbb E\\left[ \\left( \\partial_p \\varphi(p; Y, Z) \\right)^2 \\right]}{\\mathbb E\\left[ \\partial_p^2 \\varphi(p; Y, Z) \\right]^2}\n    &\\gtrsim\n    \\frac{m^4 e^{-\\frac{1}{2}m^2}}{\\left( me^{-\\frac{1}{2}m^2} \\right)^2}\n    \\gtrsim\n    m^2 e^{\\frac{1}{2}m^2}.\n\\end{aligned} This shows that the asymptotic variance grows as \\Omega\\left( m^2 e^{\\frac{1}{2}m^2} \\right), proving our desired result. Note that this is unbounded as a function of m!\nOn the other hand, let \\ell(p; X) \\overset{\\mathrm{def}}{=}\\log \\mu_p(X), and let \\ell'(p; X) \\overset{\\mathrm{def}}{=}\\partial_p \\ell(p; X). It is well-known that \\begin{aligned}\n    \\sqrt{n}(\\hat p_{\\text{MLE}} - p^\\star)\n    \\overset{\\text{D}}{\\to}\n    \\mathcal N\\left( 0, \\frac{1}{\\mathbb E[\\ell'(p^\\star; X)^2]} \\right).\n\\end{aligned} Meanwhile, we compute that \\begin{aligned}\n\\mathbb{E}[\\ell'(p^\\star; X)^2] &= \\int \\frac{(\\mu_+(X) - \\mu_-(X))^2}{\\mu_p(X)}\n\\\\\n&=\n2\\int \\frac{(\\mu_+(X) - \\mu_-(X))^2}{\\mu_+(X) + \\mu_-(X)}\\\\\n&=\n2\\left(\n\\int \\frac{(\\mu_+(X) + \\mu_-(X))^2 - 4 \\mu_+(X)\\mu_-(X)}{\\mu_+(X) + \\mu_-(X)}\n\\right)  \\\\\n&\\geq\n4\\left( 1-2\\int \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_+(X)+\\mu_-(X)} \\right) \\\\\n&\\geq\n4\\left( 1-\\int_+ \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_+(X)} - \\int_- \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_-(X)} \\right) \\\\\n&\\geq\n4\\left( 1-2\\mathbb{P}(X \\geq m) \\right) \\\\\n&\\geq\n4\\left( 1 - \\frac{1}{\\sqrt{1 + m^2}}\\exp\\left( -\\frac{m^2}{2} \\right)  \\right),\n\\end{aligned} where we have used Mills’ inequality to lower bound the Gaussian CDF. Hence, we obtain that the rescaled asymptotic variance of the MLE is bounded by \\begin{aligned}\n    \\sigma^2_{\\text{MLE}}(m)\n    &= \\frac{1}{\\mathbb E[\\ell'(p^\\star; X)^2]} \\leq\n    \\frac{1}{\n    4\\left( 1 - \\frac{e^{-\\frac{1}{2}m^2}}{\\sqrt{1+m^2}}  \\right)\n    },\n\\end{aligned} as desired.\nHaving shown both claims in the theorem, we conclude our proof. ◻"
  },
  {
    "objectID": "posts/score-matching/index.html#sec-derivatives",
    "href": "posts/score-matching/index.html#sec-derivatives",
    "title": "Challenges of Score Matching",
    "section": "Computation of score function derivatives",
    "text": "Computation of score function derivatives\n\nGeneral case\nFirst, we note that \\begin{aligned}\n    \\nabla \\log \\mu_p\n    = \\frac{\\nabla \\mu_p}{\\mu_p}\n    = \\frac{p \\nabla \\mu_+ + (1 - p) \\nabla \\mu_-}{p \\mu_+ + (1 - p) \\mu_-}\\,.\n    \\nonumber\n\\end{aligned} From this, we can compute the partial derivatives of the log-likelihood and score function with respect to p: \\begin{aligned}\n    \\partial_p \\log \\mu_p\n    &=\n    2\\frac{\\mu_+ - \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\n    &=\n    \\frac{\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-)}{\\mu_p^2}\n    \\nonumber\n    % \\\\\n    % \\partial_p^2 \\nabla \\log \\mu_p\n    % &=\n    % -2\\frac{(\\mu_+ - \\mu_-)(\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-))}{\\mu_p^3}\\,.\n    % \\nonumber\n\\end{aligned}\n\n\nSpecial case p = \\frac{1}{2}\nSpecializing these formulas to the case p = \\frac{1}{2}, we obtain that \\begin{aligned}\n    \\partial_p \\log \\mu_p\\,\\big\\vert_{p = \\frac{1}{2}}\n    &=\n    2\\frac{\\mu_+ - \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\nabla \\log \\mu_p \\,\\big\\vert_{p = \\frac{1}{2}}\n    &= \\frac{\\nabla \\mu_+ + \\nabla \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\\,\\big\\vert_{p = \\frac{1}{2}}\n    &=\n    4 \\left( \\frac{\\mu_- \\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-}{(\\mu_+ + \\mu_-)^2} \\right)\n    \\nonumber\n    % \\\\\n    % \\partial_p^2 \\nabla \\log \\mu_p\\eval_{p = \\half}\n    % &=\n    % -16 \\frac{(\\mu_+ - \\mu_-)(\\mu_-\\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-)}{(\\mu_+ + \\mu_-)^3}\\,.\n    % \\nonumber\n\\end{aligned} As functions of x, we can further simplify these expressions: \\begin{aligned}\n    \\partial_p \\log \\mu_p\\,\\big\\vert_{p = \\frac{1}{2}}\n    &=\n    2\\frac{e^{mx} - e^{-mx}}{e^{mx} + e^{-mx}}\n    = 2\\tanh(mx)\n    \\\\\n    \\nabla \\log \\mu_p \\,\\big\\vert_{p = \\frac{1}{2}}\n    (x)\n    &= -x + m \\cdot \\frac{e^{mx} - e^{-mx}}{e^{mx} + e^{-mx}}\n    = -x + m \\tanh(mx)\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\\,\\big\\vert_{p = \\frac{1}{2}}\n    (x)\n    &=\n    \\frac{8m}{(e^{mx} + e^{-mx})^2}.\n\\end{aligned} Finally, we can also compute that \\begin{aligned}\n    \\partial_p \\nabla^2 \\log \\mu_p\\,\\big\\vert_{p = \\frac{1}{2}}\n    (x)\n    &=\n    \\nabla\n    \\frac{8m}{(e^{mx} + e^{-mx})^2}\n    =\n    -\\frac{16m^2}{(e^{mx}+e^{-mx})^2}\\cdot \\tanh(mx).\n\\end{aligned}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Michael Ziyang Diao (刁子阳)",
    "section": "",
    "text": "Hi, I’m Michael! :)\nI graduated from MIT in 2023 with an M.Eng. in Computer Science (see my thesis!) and a B.S. in Electrical Engineering & Computer Science and Mathematics. I hope to use this site as a space to collect and share cool ideas I’ve stumbled across. Hopefully they interest you as well!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Challenges of Score Matching\n\n\n\n\n\n\n\nmath\n\n\nstatistics\n\n\nmachine learning\n\n\n\n\nWe motivate score matching as an alternative to maximum likelihood estimation, and consider its advantages and shortcomings.\n\n\n\n\n\n\nMay 25, 2023\n\n\nMichael Diao\n\n\n\n\n\n\nNo matching items"
  }
]