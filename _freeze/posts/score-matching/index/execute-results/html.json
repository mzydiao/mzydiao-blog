{
  "hash": "77660584d570537f16afbb15a36adf1d",
  "result": {
    "markdown": "---\ntitle: \"Challenges of Score Matching\"\nauthor: \"Michael Diao\"\ndate: \"2023-05-25\"\ncategories: [math, statistics, machine learning]\ndescription: \"We motivate *score matching* as an alternative to maximum likelihood estimation, and consider its advantages and shortcomings.\"\nabstract: \"In this post, we consider the statistical problem of *score matching*. We motivate its usage as an alternative to maximum likelihood estimation, and consider its advantages and shortcomings. We make this connection concrete by proving that for a well-separated mixture of Gaussians in one dimension, score matching is statistically inefficient compared to maximum likelihood. To our knowledge, this result is new and provides a conceptually simpler example of the statistical inefficiency of score matching than what is shown in the literature, particularly in @koehler2022statistical.\"\nbibliography: refs.bib\nformat:\n  html:\n    code-fold: true\n    toc: true\n---\n\n::: {.content-hidden}\n$$\n%%fakesubsection misc commands\n\\newcommand{\\Span}{\\textrm{span}}\n\n\\newcommand{\\dd}{\\,\\mathrm{d}}\n\n%6.437\n\\newcommand{\\iid}{\\overset{\\mathrm{i.i.d.}}\\sim}\n\\newcommand{\\di}[2]{\\left(#1 \\,\\Vert\\, #2\\right)}\n\\newcommand{\\FIop}{\\mathsf{FI}}\n\\newcommand{\\FI}[2]{\\FIop\\di{#1}{#2}}\n\\newcommand{\\KLf}[2]{D_f\\di{#1}{#2}}\n\\newcommand{\\KLop}{\\mathsf{KL}}\n\\newcommand{\\KL}[2]{\\KLop\\di{#1}{#2}}\n\\newcommand{\\tKL}[2]{\\tilde \\KLop\\di{#1}{#2}}\n\\newcommand{\\hKL}[2]{\\hat \\KLop\\di{#1}{#2}}\n\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\n\\newcommand{\\midd}{\\,\\middle\\vert\\,}\n\n%vert\n\\newcommand{\\mvert}{\\,\\bigg\\vert\\,}\n\\newcommand\\bbm\\mathbf\n\\newcommand{\\eval}{\\,\\big\\vert}\n\n\\setmathsfont(Digits){Palatino}\n%common\n\\newcommand{\\cbrt}[1]{\\sqrt[3]{#1}}\n\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n\\newcommand{\\ceiling}[1]{\\left\\lceil #1 \\right\\rceil}\n\\newcommand{\\mailto}[1]{\\href{mailto:#1}{\\texttt{#1}}}\n\\newcommand{\\ol}{\\overline}\n\\newcommand{\\ul}{\\underline}\n\\newcommand{\\wt}{\\widetilde}\n\\newcommand{\\wh}{\\widehat}\n\\newcommand{\\eps}{\\varepsilon}\n%\\renewcommand{\\iff}{\\Leftrightarrow}\n%\\renewcommand{\\implies}{\\Rightarrow}\n% \\newcommand{\\vocab}[1]{{\\bfseries\\color{blue}#1}}\n\\newcommand{\\half}{\\frac{1}{2}}\n\n%tag\n\\newcommand{\\ctag}[1]{\\tag{{\\color{Mulberry}#1}}}\n\\newcommand{\\ltag}[1]{\\tag{{\\color{Emerald}#1}}}\n\n%mathbb\n\\newcommand{\\bbA}{\\mathbb A}\n\\newcommand{\\bbB}{\\mathbb B}\n\\newcommand{\\bbC}{\\mathbb C}\n\\newcommand{\\bbD}{\\mathbb D}\n\\newcommand{\\bbE}{\\mathbb E}\n\\newcommand{\\bbF}{\\mathbb F}\n\\newcommand{\\bbG}{\\mathbb G}\n\\newcommand{\\bbH}{\\mathbb H}\n\\newcommand{\\bbI}{\\mathbb I}\n\\newcommand{\\bbJ}{\\mathbb J}\n\\newcommand{\\bbK}{\\mathbb K}\n\\newcommand{\\bbL}{\\mathbb L}\n\\newcommand{\\bbM}{\\mathbb M}\n\\newcommand{\\bbN}{\\mathbb N}\n\\newcommand{\\bbO}{\\mathbb O}\n\\newcommand{\\bbP}{\\mathbb P}\n\\newcommand{\\bbQ}{\\mathbb Q}\n\\newcommand{\\bbR}{\\mathbb R}\n\\newcommand{\\bbS}{\\mathbb S}\n\\newcommand{\\bbT}{\\mathbb T}\n\\newcommand{\\bbU}{\\mathbb U}\n\\newcommand{\\bbV}{\\mathbb V}\n\\newcommand{\\bbW}{\\mathbb W}\n\\newcommand{\\bbX}{\\mathbb X}\n\\newcommand{\\bbY}{\\mathbb Y}\n\\newcommand{\\bbZ}{\\mathbb Z}\n\n\n%mathcal\n\\newcommand{\\mA}{\\mathcal A}\n\\newcommand{\\mB}{\\mathcal B}\n\\newcommand{\\mC}{\\mathcal C}\n\\newcommand{\\mD}{\\mathcal D}\n\\newcommand{\\mE}{\\mathcal E}\n\\newcommand{\\mF}{\\mathcal F}\n\\newcommand{\\mG}{\\mathcal G}\n\\newcommand{\\mH}{\\mathcal H}\n\\newcommand{\\mI}{\\mathcal I}\n\\newcommand{\\mJ}{\\mathcal J}\n\\newcommand{\\mK}{\\mathcal K}\n\\newcommand{\\mL}{\\mathcal L}\n\\newcommand{\\mM}{\\mathcal M}\n\\newcommand{\\mN}{\\mathcal N}\n\\newcommand{\\mO}{\\mathcal O}\n\\newcommand{\\mP}{\\mathcal P}\n\\newcommand{\\mQ}{\\mathcal Q}\n\\newcommand{\\mR}{\\mathcal R}\n\\newcommand{\\mS}{\\mathcal S}\n\\newcommand{\\mT}{\\mathcal T}\n\\newcommand{\\mU}{\\mathcal U}\n\\newcommand{\\mV}{\\mathcal V}\n\\newcommand{\\mW}{\\mathcal W}\n\\newcommand{\\mX}{\\mathcal X}\n\\newcommand{\\mY}{\\mathcal Y}\n\\newcommand{\\mZ}{\\mathcal Z}\n\n%%fakesubsection own math\n\n\\DeclareMathOperator{\\epi}{epi} % epigraph\n\\DeclareMathOperator{\\relint}{relint} % relative interior\n\\DeclareMathOperator{\\interior}{int} % relative interior\n\n%%fakesubsection evan's\n\n%More commands and math operators\n\\DeclareMathOperator{\\cis}{cis}\n\\DeclareMathOperator*{\\lcm}{lcm}\n\\DeclareMathOperator*{\\argmin}{arg min}\n\\DeclareMathOperator*{\\argmax}{arg max}\n\n%Inequalities\n\\newcommand{\\cycsum}{\\sum_{\\mathrm{cyc}}}\n\\newcommand{\\symsum}{\\sum_{\\mathrm{sym}}}\n\\newcommand{\\cycprod}{\\prod_{\\mathrm{cyc}}}\n\\newcommand{\\symprod}{\\prod_{\\mathrm{sym}}}\n\n%From H113 \"Introduction to Abstract Algebra\" at UC Berkeley\n\\newcommand{\\CC}{\\mathbb C}\n\\newcommand{\\FF}{\\mathbb F}\n\\newcommand{\\NN}{\\mathbb N}\n\\newcommand{\\QQ}{\\mathbb Q}\n\\newcommand{\\RR}{\\mathbb R}\n\\newcommand{\\ZZ}{\\mathbb Z}\n\\newcommand{\\PP}{\\mathbb P}\n\\newcommand{\\EE}{\\mathbb E}\n\\newcommand{\\charin}{\\text{ char }}\n\\DeclareMathOperator{\\sign}{sign}\n\\DeclareMathOperator{\\Aut}{Aut}\n\\DeclareMathOperator{\\Inn}{Inn}\n\\DeclareMathOperator{\\Syl}{Syl}\n\\DeclareMathOperator{\\Gal}{Gal}\n\\DeclareMathOperator{\\GL}{GL} % General linear group\n% \\DeclareMathOperator{\\SL}{SL} % Special linear group\n\n%From Kiran Kedlaya's \"Geometry Unbound\"\n\\newcommand{\\abs}[1]{\\left\\lvert #1 \\right\\rvert}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n\n%From M275 \"Topology\" at SJSU\n\\newcommand{\\id}{\\mathrm{id}}\n\\newcommand{\\taking}[1]{\\xrightarrow{#1}}\n\\newcommand{\\inv}{^{-1}}\n\n%From M170 \"Introduction to Graph Theory\" at SJSU\n\\DeclareMathOperator{\\diam}{diam}\n\\DeclareMathOperator{\\ord}{ord}\n\\newcommand{\\defeq}{\\overset{\\mathrm{def}}{=}}\n\n%From the USAMO .tex filse\n\\newcommand{\\ii}{\\item}\n\n% From Math 55 and Math 145 at Harvard\n\\DeclareMathOperator{\\Ker}{Ker} % Kernel\n\\DeclareMathOperator{\\im}{im} % image\n\\DeclareMathOperator{\\rank}{rank}\n\\DeclareMathOperator{\\Spec}{Spec} % spectrum\n\\DeclareMathOperator{\\Tr}{Tr} % trace\n\\DeclareMathOperator{\\clip}{clip} % clip\n\\DeclareMathOperator{\\pr}{pr} % projection\n\\DeclareMathOperator{\\proj}{proj} % projection\n\\DeclareMathOperator{\\ext}{ext} % extension\n\\DeclareMathOperator{\\pred}{pred} % predecessor\n\\DeclareMathOperator{\\dom}{dom} % domain\n\\DeclareMathOperator{\\ran}{ran} % range\n\\DeclareMathOperator{\\supp}{supp} % support\n\\DeclareMathOperator{\\Var}{Var} % variance\n\\DeclareMathOperator{\\Cov}{Cov} % covariance\n\\DeclareMathOperator{\\Div}{div} % divergence\n\\DeclareMathOperator{\\Tan}{Tan} % tangent space\n\\DeclareMathOperator{\\diag}{diag} % diagonal\n\\DeclareMathOperator{\\prox}{prox} % proximal operator \n\n% More script letters etc.\n\\newcommand{\\SA}{\\mathscr A}\n\\newcommand{\\SB}{\\mathscr B}\n\\newcommand{\\SC}{\\mathscr C}\n\\newcommand{\\SD}{\\mathscr D}\n\\newcommand{\\SE}{\\mathscr E}\n\\newcommand{\\SF}{\\mathscr F}\n\\renewcommand{\\SL}{\\mathscr L}\n\\newcommand{\\SG}{\\mathscr G}\n\\newcommand{\\SH}{\\mathscr H}\n\\newcommand{\\OO}{\\mathcal O}\n\n\n$$\n:::\n\n\n# Introduction\n\nModern day models are incredibly rich and expressive, powering\ncontemporary advances in machine learning and statistical inference. The\nidea of modelling is that we are given some data\n$X_1, \\ldots, X_n \\in \\mX$ and want to get a handle on the underlying\ndistribution that generates the data. To do this, one approach is\n*parametric inference*: we take a family of distributions\n$\\mQ= \\left\\{ q_{\\theta} \\colon \\theta \\in \\Theta \\right\\}$ indexed by a\nparameter $\\theta \\in \\Theta$. We assume for simplicity that\n$X_1, \\ldots, X_n$ are drawn i.i.d. from $q_{\\theta^\\star}$ for some\ntrue parameter $\\theta^\\star$ where $\\theta^\\star \\in \\Theta$. Based on\nour data, we seek to produce an estimate $\\hat \\theta$ of the true\nparameter $\\theta^\\star$.\n\n## Maximum likelihood estimation\n\nOne such estimate is the *maximum likelihood estimate* (MLE), which is\nthe element of $\\Theta$ that maximizes the likelihood (or equivalently\nlog-likelihood) of the data: $$\\begin{aligned}\n    \\hat \\theta_{\\text{MLE}} \n    \\defeq \\argmax_{\\theta \\in \\Theta} \\prod_{i=1}^{n} q_\\theta(X_i) \n    = \\argmax_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} \\underbrace{\\log q_\\theta(X_i)}_{\\defeq \\ell(\\theta; X_i)}.\n\\end{aligned}$$ As $n \\to \\infty$, by the Law of Large Numbers, we have\nthat $$\\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n} \\ell(\\theta; X_i) \\overset{\\PP}{\\to} \\EE[\\ell(\\theta; X_1)] = \\EE[\\log q_\\theta(X_1)].\n\\end{aligned}$$ On the other hand, we have that $$\\begin{aligned}\n    \\EE[\\log q_{\\theta^\\star}(X_1)] - \n    \\EE[\\log q_{\\theta}(X_1)]\n    =\n    \\EE\\left[ \\log \\frac{q_{\\theta^\\star}}{q_{\\theta}}(X_1) \\right]\n    =\n    \\KL{q_{\\theta^\\star}}{q_{\\theta}},\n\\end{aligned}$$ where $\\KL{p}{q}$ denotes the KL divergence between\ndistributions $p$ and $q$. The KL divergence between two distinct\ndistributions is positive, meaning that for any $\\theta, \\theta^\\star$\nfor which $q_\\theta \\neq q_{\\theta^\\star}$, we have\n$\\KL{q_{\\theta^\\star}}{q_\\theta} > 0$. So as $n \\to \\infty$, the MLE\n$\\hat \\theta_{\\text{MLE}}$ will converge in probability to the true\nparameter $\\theta^\\star$: in other words, the MLE is a *consistent\nestimator*. Furthermore, the MLE is *asymptotically efficient*: that is,\nno other estimator attains a strictly lower variance than the MLE as\n$n \\to \\infty$.\n\nHowever, the richness of models comes at a cost. Often, the\nparameterized distribution $q_\\theta$ can only be specified up to a\nconstant of proportionality. For instance, we might specify that\n$q_\\theta(x) \\propto \\exp(-V_\\theta(x))$ for some log-potential function\n$V_\\theta \\colon \\mX\\to \\RR$. Since $q_{\\theta}$ is a probability\ndistribution, it must sum to 1, meaning that we have $$\\begin{aligned}\n    q_{\\theta} = \\frac{\\exp(-V_\\theta(x))}{Z(\\theta)},  \\qquad \\text{where} \\; Z(\\theta) \\defeq \\int_{\\mX} \\exp(-V_{\\theta}(x'))\\dd{x'}.\n\\end{aligned}$$ The issue is that for each value of $\\theta$, there is a\ndifferent *normalization constant* $Z(\\theta)$, and computing even a\nsingle normalization constant is generally intractable when the data\nspace $\\mX$ is large. Computing the MLE falls victim to this issue: if\nwe cannot compute $Z(\\theta)$, then there is no hope of computing\n$\\hat \\theta_{\\text{MLE}}$ because the objective function depends on the\nvalue of $Z(\\theta)$.\n\n## Score matching\n\nThe *score matching estimator* (SME), introduced by @hyvarinen05a,\npromises to solve this issue. The SME is defined by $$\\begin{aligned}\n    \\hat \\theta _{\\text{SME}}\n    \\defeq \\argmin_{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} \n    \\biggl[ \n    \\underbrace{\n      \\Tr(\\nabla^2 \\log q_\\theta (X_i)) + \\half \\norm{\\nabla \\log q_\\theta(X_i)}^2 \n    }_{\\defeq \\varphi (\\theta; X_i)}\n    \\biggr].\n\\end{aligned}$$ The quantity $\\nabla \\log q_\\theta$ is known as the\n*score function* of $q_\\theta$. Since the gradient is taken with respect\nto $x$ rather than $\\theta$, the normalization constant vanishes\naltogether from the objective function: hence, the score matching\nestimator indeed evades the need to normalize, giving it one\ncomputational advantage over the MLE.\n\nNow the question is: is this estimator any good? How do its statistical\nproperties compare to the MLE?\n\nAs a first consideration, the SME is indeed a consistent estimator, just\nlike the MLE. Indeed, we have that by the Law of Large Numbers,\n$$\\begin{aligned}\n    \\frac{1}{n} \\sum_{i=1}^{n} \n    \\rho(\\theta; X_i)\n    &= \n    \\frac{1}{n} \\sum_{i=1}^{n} \n    \\left[ \n    \\Tr(\\nabla^2 \\log q_\\theta (X_i)) + \\half \\norm{\\nabla \\log q_\\theta(X_i)}^2\n    \\right]\n    \\\\\n    &\\overset{\\PP}{\\to}\n    \\EE\n    \\left[ \\Tr(\\nabla^2 \\log q_\\theta (X_1)) + \\half \\norm{\\nabla \\log q_\\theta(X_1)}^2 \\right]\n    \\\\\n    &= \n    \\half \\Bigl(\\underbrace{\n    \\EE\\norm{\\nabla \\log \\frac{q_{\\theta^\\star}}{q_\\theta}(X_1)}^2\n    }_{= \\FI{q_{\\theta^\\star}}{q_\\theta}}\n    -\n    \\EE\\norm{\\nabla \\log q_{\\theta^\\star}(X_1)}^2\n    \\Bigr)\n    ,\n\\end{aligned}$$ where the last equality follows by integration by parts.\nThe first term on the last line is the *relative Fisher information*\n(FI) between $q_{\\theta^\\star}$ and $q_{\\theta}$, and is nonnegative\nwith equality iff $q_{\\theta^\\star} = q_\\theta$. Hence, asymptotically\n$\\theta^\\star$ attains minimality of the objective, meaning that\n$\\hat \\theta_{\\text{SME}}$ is indeed consistent.\n\nThe story thus far looks good. Not only does the SME relieve the\ncomputational burden of evaluating the normalization constant, but it\nalso provides a consistent estimator. Might it be the case that we can\n*always* just use the SME instead of the MLE?\n\nUnfortunately, we must dash our hopes. The core idea of score matching\nis that if the score functions $\\nabla \\log q_{\\theta^\\star}$ and\n$\\nabla \\log q_{\\theta}$ match exactly, then the distributions\n$q_{\\theta^\\star}$ and $q_{\\theta}$ must match as well. However, there\nis a key issue. The score function, being a gradient, is fundamentally a\nmeasure of *local* information about the change in the log-likelihood\nfunction. Meanwhile, it is possible for two very different distributions\nto have extremely similar log-likelihood functions (up to a constant\nshift) outside of a set of very small measure. Until enough samples land\nin that distinguishing set, score matching cannot discern the difference\nbetween these two distributions.\n\nThis is the key intuition behind the *statistical inefficiency* of score\nmatching: when $\\left\\{ q_{\\theta} \\right\\}$ is a family of\ndistributions exhibiting the aforementioned behavior --- having similar\nscore functions outside a set of negligible measure --- the SME can have\nextremely high variance compared with the MLE. As it turns out, this\nbehavior is deeply related to the maximal *log-Sobolev constant* among\ndistributions in $\\left\\{ q_\\theta \\right\\}$; see the work of\n@koehler2022statistical for a discussion.\n\nIn the sequel, we will make our intuitive argument concrete by\ndemonstrating that score matching is indeed statistically inefficient on\na simple example of *mixtures of well-separated Gaussians* --- a\nprototypical example of a distribution with large log-Sobolev constant.\n\n# Inefficiency for Mixtures of Gaussians\n\nLet $m > 0$ be a mean parameter and $p \\in [0, 1]$ be a weight\nparameter. Define the Gaussian measures $\\mu_+ = \\mN(m, 1)$ and\n$\\mu_- = \\mN(-m, 1)$, and let $\\mu_p$ be the Gaussian mixture\ndistribution defined by $\\mu_p = p \\mu_+ + (1 - p) \\mu_-$. Then the\nscore matching estimator $\\hat p_{\\text{SME}}$ for $p$ based on samples\n$X_1, \\ldots, X_n \\iid \\mu_p$ is given by: $$\\begin{aligned}\n    \\hat p_{\\text{SME}}\n    = \\argmin_{p \\in [0, 1]}\n    \\frac{1}{n} \n    \\sum_{i=1}^{n}\n    \\bigl[ \n    \\nabla^2 \\log \\mu_p (X_i) + \\half (\\nabla \\log \\mu_p (X_i))^2\n    \\bigr].\n\\end{aligned}$$ On the other hand, the MLE is given by $$\\begin{aligned}\n    \\hat p_{\\text{MLE}}\n    = \\argmin_{p \\in [0, 1]}\n    \\frac{1}{n} \n    \\sum_{i=1}^{n}\n    \\log \\mu_p (X_i) .\n\\end{aligned}$$\n\n## Inefficiency of score matching\nThe following theorem shows that the SME is\nstatistically inefficient compared to the MLE for learning the parameter\n$p$:\n\n:::: {.callout-note appearance=\"minimal\"}\n::: {#thm-inefficiency}\n# Inefficiency of score matching\n\nSuppose that $p^\\star = \\half$ and that $X \\sim \\mu_{p^\\star}$. Then as\n$n \\to \\infty$, we have that\n$$\\begin{aligned}\n        {\\sqrt{n}} (\\hat p_{\\text{SME}} - p^\\star) \\overset{\\text{D}}{\\to} \\mN(0, \\sigma^2_{\\text{SME}}(m)),\n\\end{aligned}$$\nwhere\n$\\sigma^2_{\\text{SME}}(m) \\in \\Omega(m^2 e^{-\\half m^2})$. On the other\nhand,\n$$\\begin{aligned}\n        {\\sqrt{n}} (\\hat p_{\\text{MLE}} - p^\\star) \\overset{\\text{D}}{\\to} \\mN\\left( 0, \\sigma^2_{\\text{MLE}}(m) \\right),\n\\end{aligned}$$\nwhere $\\sigma^2_{\\text{MLE}}(m)  \\in O(1)$.\n:::\n::::\n\nHence, this example of learning the weight parameter of a mixture of\none-dimensional standard Gaussians demonstrates an *extreme gap* in the\nstatistical efficiency of the SME versus the MLE: the standardized\nasymptotic variance of the SME grows as $e^{\\half m^2}$ whereas that of\nthe MLE does not grow at all (in fact, shrinks)! The idea is that the\nMLE learns the weight parameter very easily by simply looking at the\nproportion of samples landing in the positive real axis versus the\nnegative real axis, and high separation only makes this learning task\neasier. On the other hand, the SME suffers from the issue we posited\nearlier: the score functions $\\nabla \\log \\mu_p$ basically do not differ\nat all except on a small interval around 0, and the measure of this set\nis extremely small, on the order of $e^{-\\half m^2}$.\n\nIn @sec-derivatives, we compute the score function $\\nabla \\log \\mu_p$ as well as its\npartial derivatives with respect to $p$. Using these formulas, we can\nobtain our desired bounds.\nOn the other hand, before diving into the proof, we first provide an illustration in @fig-score that confirms our above intuition.\n\n### Visualizing score function for varying $p$\n\nWe plot the score functions $\\nabla \\log \\mu_p (x)$ with $m = 4.5$ for $p \\in \\{0.1, 0.5, 0.9\\}$,\nsuperimposing the mixture PDF to visually demonstrate that the score functions\nonly vary significantly on a set of negligible measure.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef gaussian_pdf(x, mean, sigma):\n    return (\n      1 / (sigma * np.sqrt(2 * np.pi)) *\n      np.exp(-(x - mean) ** 2 / (2 * sigma ** 2))\n    )\n\ndef mixture_pdf(x, mean, sigma, p):\n    # Mixture with weights p\n    mu_plus = gaussian_pdf(x, mean, sigma)\n    mu_minus = gaussian_pdf(x, -mean, sigma)\n    return (p * mu_plus + (1-p) * mu_minus)\n\ndef score_function(x, mean, sigma, p):\n    mu_plus = gaussian_pdf(x, mean, sigma)\n    mu_minus = gaussian_pdf(x, -mean, sigma)\n    pos = p * mu_plus * (- x + mean) / (sigma ** 2)\n    neg = (1-p) * mu_minus * (- x - mean) / (sigma ** 2)\n    return (pos + neg) / (mixture_pdf(x, mean, sigma, p))\n\nx = np.linspace(-10, 10, 1000)\n\n# set the mean and std\nmean = 4.5\nsigma = 1\n\n# Set the weight parameter for the Gaussian mixture\np = 0.5  # Equal weights for the two Gaussians\n\n# Compute the PDF and score function for each x value\npdf = mixture_pdf(x, mean, sigma, p)\n\n# Plotting the Gaussian mixture PDF and score function\nfig, ax1 = plt.subplots()\nblue = '#4287f5'\nax1.axhline(0, color='gray')\nax1.plot(x, pdf, blue, label=r'PDF $\\mu_{p}(x)$, $p = \\frac{1}{2}$')\nax1.set_xlabel(r'$x$')\nax1.set_ylabel('PDF')\nax1.tick_params(axis='y')\n\n# Set symmetric y limits on left\ny_min, y_max = -np.max(pdf) * 1.1, np.max(pdf) * 1.1\nax1.set_ylim(y_min, y_max)\n\n# Plot score functions for different values of p\nax2 = ax1.twinx()\nfor p in np.linspace(0.1, 0.9, 3):\n  color = plt.cm.viridis(p)\n  scores = score_function(x, mean, sigma, p)\n  ax2.plot(x, scores, color=color, label=fr'score $\\nabla \\,\\log \\mu_{{p}}(x)$, $p={p}$', )\nax2.set_ylabel('score')\nax2.tick_params(axis='y')\n\n# Display legend\nlines = ax1.get_lines() + ax2.get_lines()\nplt.legend(lines, [line.get_label() for line in lines], loc='lower left')\n\nplt.title('Gaussian Mixture PDF and Score Function')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The score function varies negligibly with $p$ outside a set of extremely small measure. Hence, learning $p$ via score matching should be extremely sample inefficient.](index_files/figure-html/fig-score-output-1.png){#fig-score width=656 height=449}\n:::\n:::\n\n\n## Proof\n\n::: proof\n# @thm-inefficiency\nDefine the *risk function* $$\\begin{aligned}\n    \\varphi(p; x)\n    &= \n    \\nabla^2 \\log \\mu_p (x) + \\half (\\nabla \\log \\mu_p (x))^2,\n\\end{aligned}$$ so that $$\\begin{aligned}\n    \\hat p_{\\text{SME}}\n    = \\argmin_{p \\in [0, 1]}\n    \\frac{1}{n} \n    \\sum_{i=1}^{n}\n    \\varphi(p, X_i)\n    .\n\\end{aligned}$$ Furthermore, denote $$\\begin{aligned}\n    \\varphi_n(p) \\defeq \n    \\frac{1}{n} \n    \\sum_{i=1}^{n}\n    \\varphi(p, X_i).\n\\end{aligned}$$ Now, since the SME is consistent, $\\hat p_{\\text{SME}}$\nwill be close to $p^\\star$ as $n \\to \\infty$. This motivates performing\na Taylor expansion of the objective function to obtain that\n$$\\begin{aligned}\n    0 \n    &=\n    \\partial_p \\varphi_n (\\hat p_{\\text{SME}})\n    \\approx\n    \\partial_p \\varphi_n (p^\\star)\n    + \n    \\partial_p^2 \\varphi_n (p^\\star) (\\hat p_{\\text{SME}} - p^\\star).\n\\end{aligned}$$ Rearranging, we obtain that $$\\begin{aligned}\n    \\sqrt{n}(\\hat p_{\\text{SME}} - p^\\star)\n    \\approx \\frac{\\sqrt{n} \\partial_p \\varphi_n (p^\\star)}{\\partial_p^2 \\varphi_n (p^\\star)}.\n\\end{aligned}$$ Let $X \\sim \\mu_{p^\\star}$. As $n \\to \\infty$, the\nCentral Limit Theorem tells us that $$\\begin{aligned}\n    \\sqrt{n} \\partial_p \\varphi_n (p^\\star)\n    \\overset{\\text{D}}{\\to} \\mN(0, \\Var\\left[ \\partial_p \\varphi(p; X) \\right])\n    = \\mN(0, \\EE\\left[ (\\partial_p \\varphi(p^\\star; X))^2 \\right]),\n\\end{aligned}$$ where the last equality is due to the fact\n$\\partial_p \\eval_{p = p^\\star}\\EE [\\varphi(p^\\star; X)] = 0$ due to\nasymptotic consistency. On the other hand, by the Law of Large Numbers,\nthe denominator converges to $$\\begin{aligned}\n    \\partial_p^2 \\varphi_n(p^\\star) = \\EE\\left[ \\partial_p^2 \\varphi(p^\\star; X) \\right].\n\\end{aligned}$$ Thus, we have that $$\\begin{aligned}\n    \\sqrt{n}(\\hat p - p^\\star)\n    \\overset{\\text{D}}{\\to}\n    \\mN\\left( 0,\n    \\frac{\\EE\\left[ \\left( \\partial_p \\varphi(p; X) \\right)^2 \\right]}{\\EE\\left[ \\partial_p^2 \\varphi(p; X) \\right]^2} \n    \\right).\n\\end{aligned}$$ In fact, we can simplify the denominator of the variance\nexpression. We have that $$\\begin{aligned}\n    \\EE\\left[ \\partial_p^2 \\varphi(p; X) \\right]\n    &= \n    \\int \\partial_p^2 \\varphi(p; x) \\dd{\\mu_p(x)}\\\\\n    &= \n    -\\int \\partial_p \\varphi(p; x) (\\partial_p \\mu_p(x))\\dd{x}\n    \\\\\n    &= \n    -\\int \\partial_p \\varphi(p; x) \\left( \\frac{\\partial_p \\mu_p(x)}{\\mu_p(x)} \\right)\\dd{\\mu_p(x)}\\\\\n    &= \n    -\\int (\\partial_p \\varphi(p; x)) (\\partial_p \\log \\mu_p (x)) \\dd{\\mu_p(x)},\n\\end{aligned}$$ where the second equality is by integration by parts. Hence, $$\\begin{aligned}\n    \\EE\\left[ \\partial_p^2 \\varphi(p; X) \\right]^2\n    &=\n    \\EE\\left[ \\partial_p \\varphi(p; X) (\\partial_p \\log \\mu_p (x)) \\right]^2.\n\\end{aligned}$$\n\nComputing the partial derivative of the risk function with respect to\n$p$, we obtain that $$\\begin{aligned}\n    \\partial_p \\varphi(p; X)\n    &=\n    \\partial_p \\nabla^2 \\log \\mu_p (X)\n    +\n    (\\nabla \\log \\mu_p(X)) (\\partial_p \\nabla \\log \\mu_p(X)).\n\\end{aligned}$$\n\nNow, we provide a lower bound on the numerator and an upper bound on the\ndenominator as follows.\n\n<details>\n  <summary>**Lower bound on numerator**.</summary>\n  Using the calculations in @sec-derivatives, we compute that \n$$\\begin{aligned}\n    \\abs{\\partial_p \\varphi(p; X)}\n    &=\n    \\abs{\n    \\partial_p \\nabla^2 \\log \\mu_p (X)\n    +\n    (\\nabla \\log \\mu_p(X)) (\\partial_p \\nabla \\log \\mu_p(X))}\n    \\\\\n    &=\n    \\abs{\n    -\\frac{16m^2}{(e^{mX} + e^{-mX})^2} \\cdot \\tanh(mX) + (-X + m \\tanh(mX)) \\cdot \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    }\n    \\\\\n    &=\n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\abs{\n    X + m \\cdot \\tanh(mX)\n    }.\n\\end{aligned}$$ Consider when $\\abs{X} \\in [\\frac{1}{2m}, \\frac{1}{m}]$.\nOn this interval, we have that $$\\begin{aligned}\n    \\frac{\\abs{\n    X + m \\cdot \\tanh(mX)\n    }}{(e^{mX} + e^{-mX})^2}\n    &\\geq\n    \\frac{m \\abs{\\tanh(mX)} - \\abs{\n    X\n    }}{(e^{mX} + e^{-mX})^2}\n    \\\\\n    &\\geq\n    \\frac{m \\tanh (1) - \\frac{1}{m}}{(e + e^{-1})^2}\n    \\\\\n    &\\gtrsim\n    m,\n\\end{aligned}$$ where the second inequality is a consequence of the triangle inequality. Thus, on this interval, we have that $$\\begin{aligned}\n    \\abs{\\partial_p \\varphi(p; X)}\n    =\n    \\frac{8m\\abs{\n    X + m \\cdot \\tanh(mX)\n    }}{(e^{mX} + e^{-mX})^2}\n    \\gtrsim m^2.\n\\end{aligned}$$ Hence, we obtain that $$\\begin{aligned}\n    \\EE\\left[ \\left( \\partial_p \\varphi(p; X) \\right)^2 \\right]\n    &= \n    \\EE\\left[ \n    \\abs{\\partial_p \\varphi(p; X)}^2\n    \\right]\n    \\\\\n    &\\geq\n    \\EE\\left[ \n    \\abs{\\partial_p \\varphi(p; X)}^2\n    \\bbm1_{\\abs{X}\\in [\\frac{1}{2m}, \\frac{1}{m}]}\n    \\right]\n    \\\\\n    &\\gtrsim\n    \\EE\\left[ \n    m^4\n    \\bbm1_{\\abs{X}\\leq [\\frac{1}{2m}, \\frac{1}{m}]}\n    \\right]\n    \\\\\n    &\\gtrsim\n    m^4 e^{-\\half m^2}.\n\\end{aligned}$$\n</details>\n\n<details>\n  <summary>**Upper bound on denominator**.</summary>\nFirst, using the work above, we have\nthat $$\\begin{aligned}\n    \\abs{\\partial_p \\varphi(p; X)}\n    &= \n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\abs{\n    X + m \\cdot \\tanh(mX)\n    }\n    \\\\\n    &\\leq\n    \\frac{8m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left( \n    \\abs{\n    X\n    } + m\n    \\right),\n\\end{aligned}$$ by the triangle inequality. On the other hand, using @sec-derivatives, we compute that $$\\begin{aligned}\n    \\abs{\\partial_p \\log \\mu_p (X)}\n    &=\n    \\abs{2\\tanh(mX)}\n    \\leq\n    2.\n\\end{aligned}$$ Hence, we find that $$\\begin{aligned}\n    \\EE\\left[ (\\partial_p \\varphi(p; X)) (\\partial_p \\log \\mu_p (X)) \\right]\n    &\\leq\n    \\EE\\left[ \\abs{\\partial_p \\varphi(p; X)} \\abs{\\partial_p \\log \\mu_p (X)} \\right]\n    \\\\\n    &\\leq\n    2\n    \\EE\\left[ \\abs{\\partial_p \\varphi(p; X)} \\right]\n    \\\\\n    &\\lesssim\n    \\EE\\left[ \n    \\frac{m}{(e^{mX} + e^{-mX})^2}\n    \\cdot\n    \\left( \n    \\abs{\n    X\n    } + m\n    \\right)\n    \\right]\n    \\\\\n    &\\lesssim\n    m\n    \\int_{0}^{\\infty}\n    \\frac{x + m}{(e^{mx} + e^{-mx})^2}\n    \\cdot\n    e^{-\\half (x - m)^2}\n    \\dd{x}\n    \\\\\n    &\\leq\n    m\n    \\int_{0}^{\\infty}\n    \\left( \n    x\n    + m\n    \\right)\n    e^{-\\half (x - m)^2-2mx}\n    \\dd{x}\n    \\\\\n    &\\lesssim\n    me^{-\\half m^2},\n\\end{aligned}$$\nwhere the last equality is a consequence of Mills' inequality (a tail bound on the Gaussian CDF).\n</details>\n\nCombining the upper and lower bounds, we find that the asymptotic\nvariance of the score matching estimator is $$\\begin{aligned}\n    \\frac{\\EE\\left[ \\left( \\partial_p \\varphi(p; Y, Z) \\right)^2 \\right]}{\\EE\\left[ \\partial_p^2 \\varphi(p; Y, Z) \\right]^2} \n    &\\gtrsim\n    \\frac{m^4 e^{-\\half m^2}}{\\left( me^{-\\half m^2} \\right)^2}\n    \\gtrsim\n    m^2 e^{\\half m^2}.\n\\end{aligned}$$ This shows that the asymptotic variance grows as\n$\\Omega\\left( m^2 e^{\\half m^2} \\right)$, proving our desired result.\nNote that this is unbounded as a function of $m$!\n\nOn the other hand, let $\\ell(p; X) \\defeq \\log \\mu_p(X)$, and let\n$\\ell'(p; X) \\defeq \\partial_p \\ell(p; X)$. It is well-known that\n$$\\begin{aligned}\n    \\sqrt{n}(\\hat p_{\\text{MLE}} - p^\\star)\n    \\overset{\\text{D}}{\\to}\n    \\mN\\left( 0, \\frac{1}{\\EE[\\ell'(p^\\star; X)^2]} \\right).\n\\end{aligned}$$ Meanwhile, we compute that $$\\begin{aligned}\n\\mathbb{E}[\\ell'(p^\\star; X)^2] &= \\int \\frac{(\\mu_+(X) - \\mu_-(X))^2}{\\mu_p(X)}\n\\\\\n&= \n2\\int \\frac{(\\mu_+(X) - \\mu_-(X))^2}{\\mu_+(X) + \\mu_-(X)}\\\\\n&= \n2\\left( \n\\int \\frac{(\\mu_+(X) + \\mu_-(X))^2 - 4 \\mu_+(X)\\mu_-(X)}{\\mu_+(X) + \\mu_-(X)}\n\\right)  \\\\\n&\\geq\n4\\left( 1-2\\int \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_+(X)+\\mu_-(X)} \\right) \\\\\n&\\geq\n4\\left( 1-\\int_+ \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_+(X)} - \\int_- \\frac{\\mu_+(X)\\mu_-(X)}{\\mu_-(X)} \\right) \\\\\n&\\geq\n4\\left( 1-2\\mathbb{P}(X \\geq m) \\right) \\\\\n&\\geq\n4\\left( 1 - \\frac{1}{\\sqrt{1 + m^2}}\\exp\\left( -\\frac{m^2}{2} \\right)  \\right),\n\\end{aligned}$$ where we have used Mills' inequality to lower bound the Gaussian CDF. Hence, we obtain that the rescaled asymptotic variance\nof the MLE is bounded by $$\\begin{aligned}\n    \\sigma^2_{\\text{MLE}}(m)\n    &= \\frac{1}{\\EE[\\ell'(p^\\star; X)^2]} \\leq \n    \\frac{1}{\n    4\\left( 1 - \\frac{e^{-\\half m^2}}{\\sqrt{1+m^2}}  \\right) \n    },\n\\end{aligned}$$ as desired.\n\nHaving shown both claims in the theorem, we conclude our proof. ◻\n:::\n\n# Appendix\n\n## Computation of score function derivatives {#sec-derivatives}\n\n### General case\n\nFirst, we note that $$\\begin{aligned}\n    \\nabla \\log \\mu_p \n    = \\frac{\\nabla \\mu_p}{\\mu_p}\n    = \\frac{p \\nabla \\mu_+ + (1 - p) \\nabla \\mu_-}{p \\mu_+ + (1 - p) \\mu_-}\\,.\n    \\nonumber\n\\end{aligned}$$ From this, we can compute the partial derivatives of the\nlog-likelihood and score function with respect to $p$: $$\\begin{aligned}\n    \\partial_p \\log \\mu_p\n    &= \n    2\\frac{\\mu_+ - \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\n    &= \n    \\frac{\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-)}{\\mu_p^2}\n    \\nonumber\n    % \\\\\n    % \\partial_p^2 \\nabla \\log \\mu_p\n    % &= \n    % -2\\frac{(\\mu_+ - \\mu_-)(\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-))}{\\mu_p^3}\\,.\n    % \\nonumber\n\\end{aligned}$$\n\n### Special case $p = \\half$\nSpecializing these formulas to the case $p = \\half$, we\nobtain that $$\\begin{aligned}\n    \\partial_p \\log \\mu_p\\eval_{p = \\half}\n    &= \n    2\\frac{\\mu_+ - \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\nabla \\log \\mu_p \\eval_{p = \\half}\n    &= \\frac{\\nabla \\mu_+ + \\nabla \\mu_-}{\\mu_+ + \\mu_-}\n    \\nonumber\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\\eval_{p = \\half}\n    &= \n    4 \\left( \\frac{\\mu_- \\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-}{(\\mu_+ + \\mu_-)^2} \\right)\n    \\nonumber\n    % \\\\\n    % \\partial_p^2 \\nabla \\log \\mu_p\\eval_{p = \\half}\n    % &=\n    % -16 \\frac{(\\mu_+ - \\mu_-)(\\mu_-\\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-)}{(\\mu_+ + \\mu_-)^3}\\,.\n    % \\nonumber\n\\end{aligned}$$ As functions of $x$, we can further simplify these\nexpressions: $$\\begin{aligned}\n    \\partial_p \\log \\mu_p\\eval_{p = \\half}\n    &= \n    2\\frac{e^{mx} - e^{-mx}}{e^{mx} + e^{-mx}} \n    = 2\\tanh(mx)\n    \\\\\n    \\nabla \\log \\mu_p \\eval_{p = \\half}\n    (x)\n    &= -x + m \\cdot \\frac{e^{mx} - e^{-mx}}{e^{mx} + e^{-mx}} \n    = -x + m \\tanh(mx)\n    \\\\\n    \\partial_p \\nabla \\log \\mu_p\\eval_{p = \\half}\n    (x)\n    &= \n    \\frac{8m}{(e^{mx} + e^{-mx})^2}.\n\\end{aligned}$$ Finally, we can also compute that $$\\begin{aligned}\n    \\partial_p \\nabla^2 \\log \\mu_p\\eval_{p = \\half}\n    (x)\n    &= \n    \\nabla\n    \\frac{8m}{(e^{mx} + e^{-mx})^2}\n    =\n    -\\frac{16m^2}{(e^{mx}+e^{-mx})^2}\\cdot \\tanh(mx).\n\\end{aligned}$$\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}