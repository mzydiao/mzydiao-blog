{
  "hash": "957e3f4fe26c7df4551268754f069104",
  "result": {
    "markdown": "---\ntitle: \"Post With Code\"\nauthor: \"Michael Diao\"\ndate: \"2023-05-23\"\ncategories: [news, code, analysis]\nimage: \"image.jpg\"\ntheme: custom.scss\n---\n\nThis is a post with executable code.\n\n::: {.cell .column-screen-inset execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axs = plt.subplots(2, 2)\nfig.set_size_inches(5, 2)\ncmaps = ['RdBu_r', 'viridis']\nfor col in range(2):\n    for row in range(2):\n        ax = axs[row, col]\n        pcm = ax.pcolormesh(\n          np.random.random((20, 20)) * (col + 1),\n          cmap=cmaps[col]\n        )\n        fig.colorbar(pcm, ax=ax)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=426 height=194}\n:::\n:::\n\n\n#### Recomputing the derivatives\n$$\n\\begin{align}\n\\mathsf{hessian}\n%&= \\partial_p\\Big\\left( \\frac{\n%\\mu_p(Y)(\\mu_+(Y)(Y - m) - \\mu_-(Y)(Y + m))\n%}{\\mu_p(Y)^2}\\\\\n%&\\qquad\\phantom{}\n%-\\frac{\n%(\\mu_+(Y) - \\mu_-(Y))(p\\mu_+(Y)(Y-m) + (1 - p)\\mu_-(Y)(Y + m))}{\\mu_p(Y)^2}\\Big \\right)\\\\\n&=\n\\partial_p^2 \\nabla \\log \\mu_p\\\\\n&= \\partial_p^2 \\frac{\\nabla \\mu_p}{\\mu_p}\\\\\n&= \\partial_p \\frac{\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-)}{\\mu_p^2}\\\\\n&= \\frac{\\mu_p^2((\\mu_+ - \\mu_-)(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_+ - \\nabla \\mu_-)(\\mu_+ - \\mu_-))}{\\mu_p^4}\\\\\n&\\qquad\\phantom{} - \\frac{(\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-))(2\\mu_p (\\mu_+ - \\mu_-))}{\\mu_p^4}\\\\\n&= -2\\frac{(\\mu_p(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_p)(\\mu_+ - \\mu_-))(\\mu_+ - \\mu_-)}{\\mu_p^3}.\n\\end{align}\n$$\nNow let's specialize these formulas for $p^\\star = \\frac{1}{2}$. We get that\n$$\n\\begin{align}\n\\mathsf{score} &= \\frac{\\nabla \\mu_1 + \\nabla \\mu_0}{\\mu_+ + \\mu_-} \\\\\n&= -\\frac{e^{-\\frac{1}{2} (Y-m)^2}(Y - m) + e^{-\\frac{1}{2} (Y+m)^2}(Y + m)}{e^{-\\frac{1}{2} (Y-m)^2} + e^{-\\frac{1}{2} (Y+m)^2}}\\\\\n&= -\\frac{e^{mY}(Y - m) + e^{-mY}(Y + m)}{e^{mY}+e^{-mY}}\\\\\n&= -Y +m \\cdot \\frac{e^{mY} - e^{-mY}}{e^{mY}+e^{-mY}}.\n\\end{align}\n$$\nNow,\n$$\n\\begin{align}\n\\mathsf{derivative} &= 2\\frac{(\\mu_+ + \\mu_-)(\\nabla \\mu_+ - \\nabla \\mu_-) - (\\nabla \\mu_+ + \\nabla \\mu_-)(\\mu_+ - \\mu_-)}{(\\mu_+ + \\mu_-)^2}\\\\\n&= 4\\left( \\frac{\\mu_- \\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-}{(\\mu_+ + \\mu_-)^2} \\right) \\\\\n&= 4 \\left( \\frac{e^{-mY}\\nabla \\mu_+ - e^{mY}\\nabla \\mu_-}{e^{mY}+e^{-mY}} \\right) \\frac{1}{\\mu_+ + \\mu_-}\\\\\n&= 4 \\left( \\frac{e^{-mY}e^{mY}(Y-m) - e^{mY}e^{-mY}(Y+m)}{(e^{mY}+e^{-mY})^2} \\right) \\\\\n&= \\frac{8m}{(e^{mY}+e^{-mY})^2}.\n\\end{align}\n$$\nAnd\n$$\n\\begin{align}\n\\mathsf{hessian}\n&= -16\\frac{(\\mu_- \\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-)(\\mu_+ - \\mu_-)}{(\\mu_+ + \\mu_-)^3}\\\\\n&= -16\\frac{(\\mu_- \\nabla \\mu_+ - \\mu_+ \\nabla \\mu_-)}{(\\mu_+ + \\mu_-)^2}\\cdot \\frac{e^{mY} -e^{-mY}}{e^{mY} + e^{-mY}}\\\\\n&= -32\\left( \\frac{m}{(e^{mY}+e^{-mY})^2} \\right) \\cdot \\frac{e^{mY} -e^{-mY}}{e^{mY} + e^{-mY}}.\n\\end{align}\n$$\nHence, we obtain that\n$$\n\\begin{align}\n\\mathbb{E}[\\ell'(p; Y, Z)^2] &=\n\\mathbb{E}\\left[ \\left( \\nabla \\log \\mu_p(Y) + Z \\right) ^2 (\\partial_p \\nabla \\log \\mu_p(Y))^2 \\right]\\\\\n&= \\mathbb{E}\\left[ (\\mathsf{score} + Z)^2 (\\mathsf{derivative})^2 \\right] \n\\\\\n\\mathbb{E}[\\ell''(p; Y, Z)] &=\n\\mathbb{E}[\n(\\mathsf{derivative})^2 + \n(\\mathsf{score} + Z)\n(\\mathsf{hessian})].\n\\end{align}\n$$\nThe roadmap is this.\n\n* Deal with the numerator by considering an interval of width $\\frac{1}{m}$.\n\t- On this interval, the derivative is bounded below by $\\frac{8m}{(e+e^{-1})^2} \\geq \\frac{2}{3}m$. On the other hand, the score plus $Z$ is bounded below by $m \\left( 1 - \\mathrm{tanh}(1) \\right) \\geq \\frac{m}{5}$.\n\t- Meanwhile, the probability is bounded by $e^{-\\frac{1}{2} m^2}$.\n\t- Combining these, we get something on the order of $O\\left( m^2 e^{-\\frac{1}{2} m^2} \\right)$.\n- Now for the denominator. Recall that we want an upper bound.\n\t- Consider the center.\n\t\t- The uniform bound for $\\mathsf{score} + Z$ we can use is $m(1+\\mathrm{tanh}(mY))$.\n\t\t- The uniform bound for $\\mathsf{hessian}$ we can use is $32m$.\n\t\t- The uniform bound for the derivative we can use is $8m$.\n\t\t- This gives us a uniform bound to the effect of $O(m^2)$ in this interval.\n\t\t- Hence, we get something on the order of $O\\left( m^2 e^{-\\frac{1}{2} (m-1)^2} \\right)$. Or if we simply bound $\\mu_p$ to be $\\leq e^{-\\frac{1}{3}m^2}$, then this is of order $O(m^2 e^{-m^2/3}).$\n\t- Consider away from the center.\n\t\t- In this case, the contribution from the first term is bounded by $O\\left( \\frac{m^2}{(e^{mY}+e^{-mY})^4} (\\mu_+ + \\mu_-) \\right).$\n\t\t- The contribution from the second term is bounded by $O\\left( \\frac{m^2}{(e^{mY}+e^{-mY})^2} (\\mu_+ + \\mu_-) \\right)$. This is $O\\left( m^2 e^{-\\frac{1}{2} (m-Y)^2 - 2mY}\\right)$ when $Y$ is positive, and when $Y$ is negative it is $O\\left( m^2e^{-\\frac{1}{2} (m+Y)^2 + 2mY} \\right)$.\n\t\t- The second term dominates.\n\t\t- Integrating this over all of space, I think the former term dominates the integral.\n\t- This gives us our desired bound.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}